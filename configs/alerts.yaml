# Configuration des alertes pour Coris Intelligent Assistant
# Syst√®me d'alertes multicouche : email, SMS, webhook, dashboard

# Configuration g√©n√©rale des alertes
global:
  # Param√®tres par d√©faut
  default_severity: "medium"
  default_timeout: "5m"
  escalation_timeout: "15m"

  # Canaux de notification
  notification_channels:
    email:
      enabled: true
      smtp_server: "${SMTP_SERVER:-smtp.gmail.com}"
      smtp_port: 587
      username: "${SMTP_USERNAME}"
      password: "${SMTP_PASSWORD}"
      from_address: "${ALERT_FROM_EMAIL:-alerts@coris.ci}"
      use_tls: true

    sms:
      enabled: true
      provider: "orange_sms" # ou autre provider SMS
      api_key: "${SMS_API_KEY}"
      sender_id: "CORIS"

    webhook:
      enabled: true
      slack_webhook: "${SLACK_WEBHOOK_URL}"
      teams_webhook: "${TEAMS_WEBHOOK_URL}"
      custom_webhook: "${CUSTOM_WEBHOOK_URL}"

    dashboard:
      enabled: true
      grafana_url: "${GRAFANA_URL:-http://localhost:3000}"

  # √âquipes et contacts
  teams:
    infrastructure:
      name: "√âquipe Infrastructure"
      email: "infra@coris.ci"
      phone: "+225XXXXXXXX"
      escalation_delay: "10m"

    ai_team:
      name: "√âquipe IA"
      email: "ai-team@coris.ci"
      phone: "+225YYYYYYYY"
      escalation_delay: "15m"

    business:
      name: "√âquipe Business"
      email: "business@coris.ci"
      phone: "+225ZZZZZZZZ"
      escalation_delay: "30m"

    on_call:
      name: "Astreinte 24/7"
      email: "oncall@coris.ci"
      phone: "+225AAAAAAAA"
      escalation_delay: "5m"

# Alertes critiques (Niveau 1 - Interruption de service)
critical_alerts:
  # Service principal down
  service_down:
    name: "Service Principal Indisponible"
    description: "L'API principale Coris Assistant ne r√©pond pas"
    severity: "critical"
    condition: |
      up{job="coris-assistant"} == 0
    duration: "1m"
    notifications:
      immediate:
        - teams: ["infrastructure", "on_call"]
        - channels: ["email", "sms", "webhook"]

    escalation:
      - delay: "5m"
        teams: ["ai_team"]
        channels: ["email", "sms"]
      - delay: "15m"
        teams: ["business"]
        channels: ["email"]

    actions:
      - restart_service
      - check_dependencies
      - enable_maintenance_mode

    runbook: "https://docs.coris.ci/runbooks/service-down"

  # Base de donn√©es inaccessible
  database_down:
    name: "Base de Donn√©es Conversations Inaccessible"
    description: "Impossible de se connecter √† PostgreSQL conversations"
    severity: "critical"
    condition: |
      up{job="postgres-conversations"} == 0
    duration: "2m"
    notifications:
      immediate:
        - teams: ["infrastructure", "on_call"]
        - channels: ["email", "sms", "webhook"]

    escalation:
      - delay: "10m"
        teams: ["ai_team", "business"]
        channels: ["email"]

    actions:
      - check_postgres_logs
      - verify_disk_space
      - attempt_connection_recovery

    runbook: "https://docs.coris.ci/runbooks/database-down"

  # ChromaDB inaccessible
  chromadb_down:
    name: "Base de Connaissances Inaccessible"
    description: "ChromaDB ne r√©pond pas - Impact sur la recherche de connaissances"
    severity: "critical"
    condition: |
      up{job="chromadb"} == 0
    duration: "3m"
    notifications:
      immediate:
        - teams: ["infrastructure", "ai_team"]
        - channels: ["email", "webhook"]

    escalation:
      - delay: "15m"
        teams: ["on_call"]
        channels: ["sms"]

    actions:
      - restart_chromadb
      - check_vector_data_integrity
      - fallback_to_basic_faq

    runbook: "https://docs.coris.ci/runbooks/chromadb-down"

  # Taux d'erreur √©lev√©
  high_error_rate:
    name: "Taux d'Erreur Critique"
    description: "Plus de 10% des requ√™tes √©chouent"
    severity: "critical"
    condition: |
      (
        sum(rate(http_requests_total{status=~"5.."}[5m])) /
        sum(rate(http_requests_total[5m]))
      ) > 0.10
    duration: "3m"
    notifications:
      immediate:
        - teams: ["ai_team", "infrastructure"]
        - channels: ["email", "webhook"]

    escalation:
      - delay: "10m"
        teams: ["on_call"]
        channels: ["sms"]

    actions:
      - analyze_error_logs
      - check_upstream_services
      - scale_if_needed

    runbook: "https://docs.coris.ci/runbooks/high-error-rate"

# Alertes d'avertissement (Niveau 2 - Performance d√©grad√©e)
warning_alerts:
  # Temps de r√©ponse √©lev√©
  high_response_time:
    name: "Temps de R√©ponse √âlev√©"
    description: "Le temps de r√©ponse m√©dian d√©passe 5 secondes"
    severity: "warning"
    condition: |
      histogram_quantile(0.5, 
        sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
      ) > 5
    duration: "5m"
    notifications:
      immediate:
        - teams: ["ai_team"]
        - channels: ["email", "webhook"]

    escalation:
      - delay: "20m"
        teams: ["infrastructure"]
        channels: ["email"]

    actions:
      - check_system_resources
      - analyze_slow_queries
      - optimize_if_needed

  # Utilisation CPU √©lev√©e
  high_cpu_usage:
    name: "Utilisation CPU √âlev√©e"
    description: "Utilisation CPU > 80% pendant plus de 10 minutes"
    severity: "warning"
    condition: |
      avg(100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
    duration: "10m"
    notifications:
      immediate:
        - teams: ["infrastructure"]
        - channels: ["email"]

    actions:
      - monitor_processes
      - check_for_cpu_intensive_operations
      - consider_scaling

  # Utilisation m√©moire √©lev√©e
  high_memory_usage:
    name: "Utilisation M√©moire √âlev√©e"
    description: "Utilisation m√©moire > 85%"
    severity: "warning"
    condition: |
      (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.85
    duration: "5m"
    notifications:
      immediate:
        - teams: ["infrastructure"]
        - channels: ["email"]

    actions:
      - check_memory_leaks
      - restart_heavy_processes
      - clear_cache_if_needed

  # Espace disque faible
  low_disk_space:
    name: "Espace Disque Faible"
    description: "Espace disque disponible < 15%"
    severity: "warning"
    condition: |
      (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.15
    duration: "5m"
    notifications:
      immediate:
        - teams: ["infrastructure"]
        - channels: ["email"]

    actions:
      - cleanup_old_logs
      - cleanup_old_backups
      - expand_storage_if_needed

  # Taux d'escalade √©lev√©
  high_escalation_rate:
    name: "Taux d'Escalade √âlev√©"
    description: "Plus de 30% des conversations sont escalad√©es"
    severity: "warning"
    condition: |
      (
        sum(increase(coris_escalations_total[1h])) /
        sum(increase(coris_conversations_total[1h]))
      ) > 0.30
    duration: "10m"
    notifications:
      immediate:
        - teams: ["ai_team", "business"]
        - channels: ["email", "webhook"]

    actions:
      - review_agent_performance
      - check_knowledge_base_coverage
      - analyze_escalation_reasons

# Alertes informatives (Niveau 3 - Monitoring)
info_alerts:
  # Tokens OpenAI √©lev√©s
  high_token_usage:
    name: "Consommation Tokens OpenAI √âlev√©e"
    description: "Consommation de tokens > 80% de la limite quotidienne"
    severity: "info"
    condition: |
      sum(increase(coris_openai_tokens_total[1d])) > 400000
    duration: "1h"
    notifications:
      immediate:
        - teams: ["ai_team", "business"]
        - channels: ["email"]

    actions:
      - monitor_token_usage_patterns
      - optimize_prompts_if_needed
      - adjust_limits_if_necessary

  # Nouveau d√©ploiement
  deployment_notification:
    name: "Nouveau D√©ploiement D√©tect√©"
    description: "Une nouvelle version a √©t√© d√©ploy√©e"
    severity: "info"
    condition: |
      changes(coris_build_info[5m]) > 0
    duration: "1m"
    notifications:
      immediate:
        - teams: ["ai_team", "infrastructure"]
        - channels: ["webhook"]

    actions:
      - monitor_post_deployment_metrics
      - verify_health_checks
      - check_for_regressions

  # Pic de trafic
  traffic_spike:
    name: "Pic de Trafic D√©tect√©"
    description: "Augmentation du trafic > 200% par rapport √† la normale"
    severity: "info"
    condition: |
      sum(rate(http_requests_total[5m])) > (
        avg_over_time(sum(rate(http_requests_total[5m]))[1d:1h]) * 3
      )
    duration: "10m"
    notifications:
      immediate:
        - teams: ["infrastructure", "business"]
        - channels: ["email", "webhook"]

    actions:
      - monitor_system_performance
      - prepare_for_scaling
      - analyze_traffic_source

# Configuration des templates de messages
message_templates:
  email:
    critical: |
      üö® ALERTE CRITIQUE - {{ .alert_name }}

      **Service:** Coris Intelligent Assistant
      **S√©v√©rit√©:** {{ .severity }}
      **Heure:** {{ .timestamp }}

      **Description:** {{ .description }}

      **Condition:** {{ .condition }}

      **Actions recommand√©es:**
      {{ range .actions }}
      - {{ . }}
      {{ end }}

      **Runbook:** {{ .runbook }}

      **√âquipe assign√©e:** {{ .team }}

      --
      Syst√®me d'alertes Coris CI

    warning: |
      ‚ö†Ô∏è ALERTE - {{ .alert_name }}

      **Service:** Coris Intelligent Assistant
      **S√©v√©rit√©:** {{ .severity }}
      **Heure:** {{ .timestamp }}

      **Description:** {{ .description }}

      **Actions sugg√©r√©es:**
      {{ range .actions }}
      - {{ . }}
      {{ end }}

      **√âquipe assign√©e:** {{ .team }}

  slack:
    critical: |
      üö® *ALERTE CRITIQUE*

      *Service:* Coris Intelligent Assistant
      *Alerte:* {{ .alert_name }}
      *S√©v√©rit√©:* {{ .severity }}

      {{ .description }}

      <{{ .runbook }}|Voir le runbook>

    warning: |
      ‚ö†Ô∏è *Alerte*

      *Service:* Coris Intelligent Assistant
      *Alerte:* {{ .alert_name }}

      {{ .description }}

  sms: |
    CORIS ALERT: {{ .alert_name }} - {{ .severity }}
    {{ .description }}
    Equipe: {{ .team }}

# Configuration de la r√©solution automatique
auto_resolution:
  enabled: true
  timeout: "1h" # R√©solution automatique apr√®s 1h sans d√©clenchement

  conditions:
    service_recovery: |
      up{job="coris-assistant"} == 1
    database_recovery: |
      up{job="postgres-conversations"} == 1
    error_rate_normal: |
      (
        sum(rate(http_requests_total{status=~"5.."}[5m])) /
        sum(rate(http_requests_total[5m]))
      ) < 0.05

# Configuration des horaires d'astreinte
on_call_schedule:
  timezone: "Africa/Abidjan"

  business_hours:
    weekdays: "08:00-18:00"
    saturday: "09:00-13:00"
    sunday: "off"

  escalation_rules:
    business_hours:
      level_1: "ai_team"
      level_2: "infrastructure"
      level_3: "on_call"

    after_hours:
      level_1: "on_call"
      level_2: "infrastructure"
      level_3: "ai_team"

# Int√©gration avec des syst√®mes externes
integrations:
  pagerduty:
    enabled: false
    api_key: "${PAGERDUTY_API_KEY}"
    service_key: "${PAGERDUTY_SERVICE_KEY}"

  opsgenie:
    enabled: false
    api_key: "${OPSGENIE_API_KEY}"
    team: "coris-team"

  jira:
    enabled: true
    url: "${JIRA_URL}"
    username: "${JIRA_USERNAME}"
    api_token: "${JIRA_API_TOKEN}"
    project_key: "CORIS"
    issue_type: "Bug"

# M√©tadonn√©es
metadata:
  version: "1.0.0"
  last_updated: "2024-01-15"
  owner: "Infrastructure Team"
  contact: "infra@coris.ci"
